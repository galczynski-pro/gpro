<!-- Modal -->
<div class="modal modal-xl fade" id="modalModels" tabindex="-1" aria-labelledby="modalModelsLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<h1 class="modal-title fs-5" id="modalModelsLabel">Description of models</h1>
				<button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
			</div>
			<div class="modal-body">

				<table class="table table-striped table-hover">
					<thead class="thead-dark">
						<tr>
							<th scope="col" width="160">Model</th>
							<th scope="col">Description</th>
							<th scope="col">Max tokens</th>
							<th scope="col">Training data</th>
						</tr>
					</thead>
					<tbody>
						<tr>
							<td>gpt-4o</td>
							<td>GPT-4o: Our high-intelligence flagship model for complex, multi-step tasks. GPT-4o is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13.</td>
							<td>128,000 tokens</td>
							<td>Up to Oct 2023</td>
						</tr>
						<tr>
							<td>gpt-4o-2024-05-13</td>
							<td>gpt-4o currently points to this version. This version supports complex tasks with 128,000 tokens for context.</td>
							<td>128,000 tokens</td>
							<td>Up to Oct 2023</td>
						</tr>
						<tr>
							<td>gpt-4o-2024-08-06</td>
							<td>Latest snapshot that supports Structured Outputs. Ideal for complex, multi-step tasks with enhanced structured output support.</td>
							<td>128,000 tokens</td>
							<td>Up to Oct 2023</td>
						</tr>
						<tr>
							<td>chatgpt-4o-latest</td>
							<td>Dynamic model continuously updated to the current version of GPT-4o in ChatGPT. Best suited for research and evaluation.</td>
							<td>128,000 tokens</td>
							<td>Up to Oct 2023</td>
						</tr>
						<tr>
							<td>gpt-4o-mini</td>
							<td>GPT-4o-mini: Our affordable and intelligent small model for fast, lightweight tasks. Cheaper and more capable than GPT-3.5 Turbo.</td>
							<td>128,000 tokens</td>
							<td>Up to Oct 2023</td>
						</tr>
						<tr>
							<td>gpt-4o-mini-2024-07-18</td>
							<td>gpt-4o-mini currently points to this version. Best suited for smaller tasks with a reduced token limit, maintaining high intelligence and speed.</td>
							<td>128,000 tokens</td>
							<td>Up to Oct 2023</td>
						</tr>
						<tr>
							<td>gpt-4-turbo</td>
							<td>The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling.</td>
							<td>128,000 tokens</td>
							<td>Up to Dec 2023</td>
						</tr>
						<tr>
							<td>gpt-4-turbo-2024-04-09</td>
							<td>GPT-4 Turbo with Vision model. Vision requests can now use JSON mode and function calling.</td>
							<td>128,000 tokens</td>
							<td>Up to Dec 2023</td>
						</tr>
						<tr>
							<td>gpt-4-turbo-preview</td>
							<td>GPT-4 Turbo preview model, intended for research and testing with enhanced capabilities.</td>
							<td>128,000 tokens</td>
							<td>Up to Dec 2023</td>
						</tr>
						<tr>
							<td>gpt-4-1106-preview</td>
							<td>The latest GPT-4 model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.</td>
							<td>128,000 tokens</td>
							<td>Up to Apr 2023</td>
						</tr>
						<tr>
							<td>gpt-4</td>
							<td>More capable than any GPT-3.5 model, able to do more complex tasks, and optimized for chat.</td>
							<td>8,192 tokens</td>
							<td>Up to Sep 2021</td>
						</tr>
						<tr>
							<td>gpt-4-0613</td>
							<td>Snapshot of gpt-4 from June 13th 2023 with function calling data.</td>
							<td>8,192 tokens</td>
							<td>Up to Sep 2021</td>
						</tr>
						<tr>
							<td>gpt-4-32k</td>
							<td>Same capabilities as the base gpt-4 mode but with 4x the context length.</td>
							<td>32,768 tokens</td>
							<td>Up to Sep 2021</td>
						</tr>
						<tr>
							<td>gpt-4-32k-0613</td>
							<td>Snapshot of gpt-4-32 from June 13th 2023 with function calling data.</td>
							<td>32,768 tokens</td>
							<td>Up to Sep 2021</td>
						</tr>
						<tr>
							<td>gpt-3.5-turbo</td>
							<td>Most capable GPT-3.5 model and optimized for chat at 1/10th the cost of text-davinci-003.</td>
							<td>4,096 tokens</td>
							<td>Up to Sep 2021</td>
						</tr>
						<tr>
							<td>gpt-3.5-turbo-0613</td>
							<td>Snapshot of gpt-3.5-turbo from June 13th 2023 with function calling data.</td>
							<td>4,096 tokens</td>
							<td>Up to Sep 2021</td>
						</tr>
						<tr>
							<td>gpt-3.5-turbo-16k</td>
							<td>Same capabilities as the standard gpt-3.5-turbo model but with 4 times the context length.</td>
							<td>16,384 tokens</td>
							<td>Up to Sep 2021</td>
						</tr>
						<tr>
							<td>gpt-3.5-turbo-16k-0613</td>
							<td>Snapshot of gpt-3.5-turbo-16k from June 13th 2023 with function calling data.</td>
							<td>16,384 tokens</td>
							<td>Up to Sep 2021</td>
						</tr>
						<tr>
							<td>text-davinci-003</td>
							<td>Can do any language task with better quality, longer output, and consistent instruction-following than the curie, babbage, or ada models.</td>
							<td>4,097 tokens</td>
							<td>Up to Sep 2021</td>
						</tr>                
					</tbody>
				</table>

			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Close</button>
			</div>
		</div>
	</div>
</div>
